{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwwNkWXdkTskH+AONE/Hte",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jagadeeshgunti2004/Projects/blob/main/Gemini_Ai_Image_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NJEDVcq1XjgB"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "def to_markdown(text):\n",
        "    text = text.replace('*', ' - ')\n",
        "    return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "Dn1YOedaYWxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "client=genai.Client(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "0nkFdd9RZVbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL.Image\n",
        "import google.generativeai as genai\n",
        "img = PIL.Image.open('image1.jpeg')\n",
        "img\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "response = model.generate_content([\"Write a short, engaging blog post based on this picture. It should include a description of the meal in the photo and talk about my journey meal prepping.\", img],stream=True)\n",
        "response.resolve()"
      ],
      "metadata": {
        "id": "YxWJNNP3Zjvx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "Z5AJKdD8bCak",
        "outputId": "6007d1ff-babc-4867-dc3c-7438abb4ad46"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> That's a great logo!  However, it doesn't show a meal, so I'll need to create a description of a healthy, earth-friendly meal to accompany the blog post.\n> \n> \n>  -  - Title: My Green Journey: From Meal Prep Chaos to Earth-Conscious Eats -  - \n> \n> That little green globe with its leafy embrace? That's my inspiration.  It represents my recent journey into mindful eating and sustainable meal prepping. For years, my lunches were a chaotic mix of takeout and whatever I could grab quickly.  It wasn't good for my body, and definitely not good for the planet.\n> \n> So I decided to change things.  This week's meal prep victory?  A gorgeous  -  - quinoa salad with roasted sweet potatoes, chickpeas, kale, and a lemon-tahini dressing -  - .  The sweet potatoes are locally sourced, the kale from my own little balcony garden (baby steps!), and the quinoa is organic. It’s bursting with color, flavor, and a whole lot of feel-good vibes.  Think vibrant orange, deep green, and pops of creamy white.  It’s packed with protein, fiber, and all the goodness my body craves.\n> \n> My meal prep journey hasn’t been without its bumps.  My first attempt involved slightly burnt broccoli and a dressing that tasted suspiciously like dish soap.  But I persevered!  The key, I've found, is planning.  I now dedicate a couple of hours on Sundays to chopping, roasting, and assembling my meals for the week.  It’s a small investment that pays off big time in terms of health, budget, and reducing my environmental footprint.\n> \n> This quinoa salad is just the beginning. My goal is to continue exploring seasonal, locally-sourced ingredients and minimizing food waste.  Want to join me on this green journey? Share your favorite sustainable meal prep tips in the comments below!\n"
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zY94VS2MqwU",
        "outputId": "b991af1c-036a-4332-83f4-f9866f04a1d6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"Generate an accurate caption for this image.\", img])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "av57K6V2cpHP",
        "outputId": "6822601f-196d-4eff-9c7d-bbffa57d0fdb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are a few caption options for the image, depending on the intended use:\n",
            "\n",
            "**Option 1 (Simple & General):**\n",
            "\n",
            "> Protecting our planet.\n",
            "\n",
            "**Option 2 (Slightly more detailed):**\n",
            "\n",
            ">  A green future for a healthy Earth.\n",
            "\n",
            "**Option 3 (Focus on sustainability):**\n",
            "\n",
            "> Sustainable practices for a greener world.\n",
            "\n",
            "**Option 4 (If it's a logo for a company):**\n",
            "\n",
            "> [Company Name] – Committed to environmental sustainability.\n",
            "\n",
            "\n",
            "The best option will depend on the context in which you're using the image.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "image_path=\"Image2.jpg\"\n",
        "image = Image.open(image_path)\n",
        "response = model.generate_content([\"Describe this image in detail.\",image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "_9JY_7YCegT9",
        "outputId": "9fe834d9-5f43-466c-fea6-0b7ec51a7769"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a description of the image:\n",
            "\n",
            "Close-up view of a woman with shoulder-length, curly brown hair. \n",
            "\n",
            "\n",
            "She is smiling and pointing with her index finger to her left, indicating something off-camera. Her expression is friendly and engaging. She appears to be of South Asian descent.\n",
            "\n",
            "\n",
            "She is wearing a teal-colored three-quarter sleeve top with a subtle, gold, patterned design. The top appears to be made of a soft, possibly cotton-like material. The top has a simple, slightly v-neck collar. Her arms are crossed, with one arm bent to make the pointing gesture. She also appears to be wearing small earrings that are not clearly visible.\n",
            "\n",
            "\n",
            "The background is a plain, bright white, which makes the woman and her clothing the focal point of the image. The lighting is even and soft, avoiding harsh shadows. The overall impression is a clean, bright, and friendly portrait.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"What emotions can you detect in this image?\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "gx1LpBMegrTM",
        "outputId": "fb068435-5a26-4c0a-f6e7-8c9a4d8a0a27"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The woman in the image appears to be expressing happiness, confidence, and helpfulness.  Her smile is genuine and her posture is open and inviting.  The gesture of pointing suggests she is offering information or direction.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"logo1.jpg\"\n",
        "image = Image.open(image_path)\n",
        "response = model.generate_content([\"Identify the brand or company associated eith the logo..\",image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "u5w3X09qkSTf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "390e1134-acf3-4dfd-e851-faa3eddf118d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That's the logo for **Amazon**.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"product.jpg\"\n",
        "image = Image.open(image_path)\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "response = model.generate_content([\"What product is shown in this image?\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "-3XLGYnwkSgH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab4e7cba-7799-4844-e5df-c3b5163690b1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That's a pair of black over-ear headphones.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"Suggest similar products to this one.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "PpyLfG-QkGGM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "f6df6c17-94c3-44c4-e15c-c9606d65d663"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are some similar products to the pictured black over-ear headphones:\n",
            "\n",
            "**Focusing on Style and Features:**\n",
            "\n",
            "* **Other over-ear headphones with a similar design:** Look for other black over-ear headphones with a similar sleek, minimalist design.  Brands like Sony, Bose, Audio-Technica, Sennheiser, and JBL all produce models in this style.  Pay attention to the earcup size and headband padding as these affect comfort.\n",
            "* **Noise-canceling headphones:** If the pictured headphones have noise cancellation (it's not clear from the image), similar noise-canceling headphones from the brands mentioned above would be good alternatives.  Noise cancellation is a popular feature in this style of headphone.\n",
            "* **Wireless headphones:** If the pictured headphones are wireless (again, not clear from the image), you can search for wireless over-ear headphones.  Most modern headphones offer Bluetooth connectivity.\n",
            "\n",
            "**Focusing on Price Point:**\n",
            "\n",
            "* **Budget-friendly alternatives:**  Brands like Anker, Soundcore, and TaoTronics offer good quality over-ear headphones at lower price points. They might not have all the premium features of higher-end models but offer decent sound and comfort.\n",
            "* **Premium alternatives:** If you're looking for a step up in sound quality, features, and materials, explore the high-end offerings from brands like Bowers & Wilkins, Beyerdynamic, and Audeze.\n",
            "\n",
            "\n",
            "**To find the best alternatives, I need more information:**\n",
            "\n",
            "* **Is it wireless or wired?**\n",
            "* **Does it have noise cancellation?**\n",
            "* **What is your budget?**\n",
            "* **What is your priority? (e.g., sound quality, comfort, noise cancellation, portability)**\n",
            "\n",
            "Once you provide this information, I can give you more specific and helpful recommendations.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"invoice.jpg\"\n",
        "image = Image.open(image_path)\n",
        "response = model.generate_content([\"Extract the price from this image.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "uX1UOdj2Pocs",
        "outputId": "03d9fc25-9983-4e3e-a2b7-e0b1df7c2043"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The price of each item is $10.00.  The sub-total is $100.00, the tax is 10%, and the grand total is $100.00.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"Extract the price, currency, and any discounts from this image.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "OXtYVI9kS915",
        "outputId": "4319b15d-592e-476a-d8ae-d36359e642a0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's the extracted information from the provided invoice image:\n",
            "\n",
            "* **Price:** $10.00 (per item)\n",
            "* **Currency:** USD ($)\n",
            "* **Discounts:** No discounts are listed on the invoice.  There is a 10% tax applied.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"bicycle.jpg\"\n",
        "image = Image.open(image_path)\n",
        "response = model.generate_content([\"Identify all objects in this image.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "LRsoKh8WTCgK",
        "outputId": "615b9f79-3d99-4aad-b9af-262722743ed3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are the objects I see in the image:\n",
            "\n",
            "* **Two men** are riding bicycles.  One is wearing a blue shirt and camouflage shorts; the other is wearing a grey shirt, jeans, and a red cap.\n",
            "* **Two bicycles:**  One is mostly yellow and black; the other is white.\n",
            "* **A motorcycle** is parked to the left of the frame.\n",
            "* **A building:** A building with a light beige facade and a roll-up door.  It has a window with a security grate.\n",
            "* **Chairs:** Two red plastic chairs are visible inside the building.\n",
            "* **A man:** A man is sitting in the background of the building, inside the doorway.\n",
            "* **Grass/weeds:** some weeds and grass are visible on the curb.\n",
            "* **Road/street:** The men are riding their bicycles on a wet road.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image=Image.open(\"items.jpg\")\n",
        "response=model.generate_content([\"List all objects in this image and count how many of each are present.\",image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "-VeWsDysThM3",
        "outputId": "e88def5f-0752-49c2-88ec-11008467e4a7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a list of the objects in the image and their counts:\n",
            "\n",
            "**Countables:**\n",
            "\n",
            "* Eggs: 3\n",
            "* Banana: 1\n",
            "* Olive: 2\n",
            "* Fries: 1 (portion/serving)\n",
            "* Burger: 1\n",
            "* Hot dog: 1\n",
            "* Apple: 1\n",
            "* Carrots: 2\n",
            "* Tomatoes: 3\n",
            "* Watermelon: 1\n",
            "\n",
            "**Uncountables:**\n",
            "\n",
            "* Milk: 1 (bottle/carton)\n",
            "* Flour: 1 (bag)\n",
            "* Salt: 1 (container)\n",
            "* Sugar: 1 (bowl)\n",
            "* Jam: 1 (jar)\n",
            "* Meat: 2 (slices)\n",
            "* Rice: 1 (bowl)\n",
            "* Honey: 1 (jar)\n",
            "* Tea: 1 (cup)\n",
            "* Cheese: 1 (slice)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install youtube-transcript-api pytube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyG8ZrMLUcnX",
        "outputId": "79f80c4f-629c-48b9-f50b-36a23e076123"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube-transcript-api\n",
            "  Downloading youtube_transcript_api-1.0.1-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (0.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (2025.1.31)\n",
            "Downloading youtube_transcript_api-1.0.1-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube, youtube-transcript-api\n",
            "Successfully installed pytube-15.0.0 youtube-transcript-api-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "def get_youtube_transcript(video_url):\n",
        "    \"\"\"Fetches the transcript of a YouTube video.\"\"\"\n",
        "    video_id = video_url.split(\"v=\")[1].split(\"&\")[0]\n",
        "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "    full_text = \" \".join([t[\"text\"] for t in transcript])\n",
        "    return full_text\n",
        "video_url = \"https://www.youtube.com/watch?v=unYDoA8QGH0&list=PLWEpztHwA4ZT2QlHC74oIz4MsawcvE-QX\"\n",
        "video_transcript = get_youtube_transcript(video_url)\n",
        "print(\"Transcript:\\n\", video_transcript[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llfYDrEbU1RK",
        "outputId": "1945e4b6-7195-4145-e960-6b605562259e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcript:\n",
            " hi guys today I'm going to introduce you what is machine learning uh these are my presentation content what is machine learning what are the different applications of machine learning different types of machine learning and how to build a machine learning system or model then various kinds of algorithms and later on in this series we are going to take a Hands-On you know case studies or doing programming for various kinds of up algorithms so what is machine learning so machine learning is nothin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "7oLm5AJVVR6l"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_video_insights(text):\n",
        "    \"\"\"Extracts key insights from the YouTube video transcript.\"\"\"\n",
        "    model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "    prompt = f\"Extract the key takeaways and insights from this YouTube video:\\n\\n{text}\"\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text\n",
        "\n",
        "insights = extract_video_insights(video_transcript)\n",
        "print(\"Key Insights:\\n\", insights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        },
        "id": "XKrafz2gWevF",
        "outputId": "b2157805-2212-405d-c73b-8f4a8f748f5f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key Insights:\n",
            " This YouTube video provides an introduction to machine learning. Here are the key takeaways and insights:\n",
            "\n",
            "**What is Machine Learning?**\n",
            "\n",
            "* **Learning from Data:** Machine learning is essentially about enabling computers to learn from data without explicit programming.  It's a subfield of artificial intelligence.  The data used for learning is called training data or experience.\n",
            "* **Building Predictive Models:**  The process involves applying machine learning algorithms to training data to build a model. This model can then be used to make predictions on new, unseen data.\n",
            "* **Arthur Samuel's Definition:**  A concise definition provided is:  \"A field of study that gives computers the ability to learn without being explicitly programmed.\"\n",
            "* **Formal Definition:** A computer program learns from experience (E) regarding a task (T) as measured by performance (P), if its performance on T improves with experience E.\n",
            "\n",
            "**Applications of Machine Learning:**\n",
            "\n",
            "The video highlights several diverse applications:\n",
            "\n",
            "* **Speech Recognition:**  Powering applications like Siri, Alexa, and Google Assistant.\n",
            "* **Web Search Systems:**  Improving search relevance using algorithms like Naive Bayes.\n",
            "* **Recommendation Systems:** Suggesting products or other items to users.\n",
            "* **Computer Vision:**  Understanding the content of images and videos.\n",
            "* **Information Retrieval:**  Processing vast amounts of data (like Google Search) to deliver relevant information.\n",
            "* **Fraud Detection:** Identifying malicious activities online.\n",
            "\n",
            "**Types of Machine Learning:**\n",
            "\n",
            "The video categorizes machine learning into three main types:\n",
            "\n",
            "* **Supervised Learning:**  The training data is labeled, meaning the desired outcome is known.  This is further divided into:\n",
            "    * **Classification:** Predicting categorical outcomes (e.g., spam/not spam).\n",
            "    * **Regression:** Predicting continuous outcomes (e.g., house prices).\n",
            "* **Unsupervised Learning:** The training data is unlabeled.  The goal is to discover patterns and structures in the data. Examples include clustering and dimensionality reduction.\n",
            "* **Reinforcement Learning:** An agent learns through trial and error by interacting with an environment, receiving rewards or penalties for its actions.  Games and robotics are common applications.\n",
            "\n",
            "\n",
            "**Building a Machine Learning Model: The Process**\n",
            "\n",
            "The video outlines a typical machine learning workflow:\n",
            "\n",
            "1. **Data Preprocessing:** Cleaning and preparing the data (handling missing values, scaling features, encoding categorical variables, feature selection, dimensionality reduction).\n",
            "2. **Algorithm Selection:** Choosing an appropriate algorithm based on the problem type (classification, regression, etc.).\n",
            "3. **Model Training:** Applying the chosen algorithm to the training data to build a model.\n",
            "4. **Model Evaluation:** Assessing the model's performance using various metrics (accuracy, precision, recall, etc.).  The presenter emphasizes building multiple models and comparing their performance.\n",
            "\n",
            "**Key Terminology:**\n",
            "\n",
            "The video defines essential machine learning terms like features, attributes, samples, instances, observations, target variable, and response variable.  The Iris dataset is mentioned as a common example used in practice.\n",
            "\n",
            "\n",
            "In summary, the video provides a solid foundational overview of machine learning, covering its core concepts, applications, types, and the process of building a model.  It emphasizes the importance of practical application and encourages viewers to continue learning through hands-on exercises.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_question_about_video(text, question):\n",
        "    \"\"\"Answers user questions about the YouTube video content.\"\"\"\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "    prompt = f\"The following is a YouTube video transcript:\\n\\n{text}\\n\\nAnswer this question based on the content:\\n{question}\"\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text\n",
        "question = \"What is the main topic discussed in the video?\"\n",
        "answer = ask_question_about_video(video_transcript, question)\n",
        "print(\"Answer:\\n\", answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "31Jtv9v-Wjn0",
        "outputId": "6bcbbbf4-45ed-4dc6-e850-4c4643c27e75"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer:\n",
            " The main topic of the YouTube video is an introduction to machine learning.  The speaker covers what machine learning is, its various applications, different types of machine learning (supervised, unsupervised, and reinforcement learning), and the process of building a machine learning model.  The video also touches upon specific algorithms and promises hands-on case studies in future videos.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "65hrVRB9YqVD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}