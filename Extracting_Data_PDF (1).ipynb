{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a806bd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in c:\\users\\gunti\\anaconda3\\lib\\site-packages (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2b226b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "from PyPDF2 import PdfFileReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6dbf0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages: 35\n",
      " \n",
      " \n",
      " Development  Plan for Greater Mumbai 2014‐2034                                                                                                                                                                                                                                                      \n",
      "Acknowledgements  \n",
      "The Consultant  wishes to thank the following  individuals  from the Municipal  Corporation  of \n",
      "Greater Mumbai for their invaluable  support, insights and contributions  towards ‘Working  Paper 1 \n",
      "– Preparation  of Base Map’ for the preparation  of the Development  Plan for Greater Mumbai \n",
      "2014‐34. \n",
      " Mr. Subodh Kumar, IAS, Municipal  Commissioner;  \n",
      " Mr. Rajeev Kuknoor, Chief Engineer Development  Plan; \n",
      " Mr. Sudhir Ghate, Deputy Chief Engineer Development  Plan; \n",
      " Mr. A.G. Marathe, Deputy Chief Engineer Development  Plan; \n",
      " Mr. R. Balachandran,  Executive  Engineer and Town Planning Officer, Development  Plan. \n",
      " Our gratitude  to the following  experts for their invaluable  insights and support: \n",
      " \n",
      "Mr. V.K Phatak, Former Chief Town Planner (MMRDA);  \n",
      " Mr. A.N Kale, Former Chief Engineer, (DP); \n",
      " Mr. A. S Jain Former Dy. Chief Engineer, (DP). \n",
      " We wish to especially  thank MCGM officers, Mr. Jagdish Talreja, Mr. Dinesh Naik, Mr. Hiren \n",
      "Daftardar,  Ms. Anita Naik for their continual  support since the\n",
      " beginning  of the project and their \n",
      "help towards familiarization  and data collection.  They have been instrumental  in helping to \n",
      "contact various MCGM departments  as well as in helping to establish contact with personnel  from \n",
      "other government  departments  and organizations.  Many thanks for the MCGM team, for \n",
      "deploying  personnel,  particularly  Mr. Prasad Gharat, on extensive  field visits that have helped in \n",
      "understanding  actual ground conditions.  \n",
      " \n",
      "We apologize  if we have inadvertently  omitted anyone to whom acknowledgement  is due. We hope \n",
      "and anticipate  the work's usefulness  for the intended purpose. \n",
      " \n"
     ]
    }
   ],
   "source": [
    "pdf = open(\"file1pdf.pdf\",\"rb\")\n",
    "pdf_reader = PyPDF2.PdfReader(pdf)\n",
    "print(\"Number of pages:\",len(pdf_reader.pages))\n",
    "page = pdf_reader.pages[1]\n",
    "print(page.extract_text())\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01565f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2, urllib, nltk\n",
    "from io import BytesIO\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e77d20be",
   "metadata": {},
   "outputs": [],
   "source": [
    "wFile = urllib.request.urlopen('http://www.udri.org/pdf/02%20working%20paper%201.pdf')\n",
    "pdfreader = PyPDF2.PdfReader(BytesIO(wFile.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b0ef42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pageObj = pdfreader.pages[2]\n",
    "page2 = pageObj.extract_text()\n",
    "punctuations = ['(',')',';',':','[',']',',','...','.']\n",
    "tokens = word_tokenize(page2)\n",
    "stop_words = stopwords.words('english')\n",
    "keywords = [word for word in tokens if not word in stop_words and not word in punctuations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aacd665c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Development',\n",
       " 'Plan',\n",
       " 'Greater',\n",
       " 'Mumbai',\n",
       " '2014‐2034',\n",
       " 'Table',\n",
       " 'Contents',\n",
       " 'The',\n",
       " 'Consultant',\n",
       " 'wishes',\n",
       " 'thank',\n",
       " 'following',\n",
       " 'individuals',\n",
       " 'Municipal',\n",
       " 'Corporation',\n",
       " 'Greater',\n",
       " 'Mumbai',\n",
       " 'invaluable',\n",
       " 'support',\n",
       " 'insights',\n",
       " 'contributions',\n",
       " 'towards',\n",
       " '‘',\n",
       " 'Working',\n",
       " 'Paper',\n",
       " '1',\n",
       " '–',\n",
       " 'Preparation',\n",
       " 'Base',\n",
       " 'Map',\n",
       " '’',\n",
       " 'preparation',\n",
       " 'Development',\n",
       " 'Plan',\n",
       " 'Greater',\n",
       " 'Mumbai',\n",
       " '2014‐34',\n",
       " '.............................................................................................................................',\n",
       " '..............',\n",
       " '3',\n",
       " 'Our',\n",
       " 'gratitude',\n",
       " 'following',\n",
       " 'experts',\n",
       " 'invaluable',\n",
       " 'insights',\n",
       " 'support',\n",
       " '............................',\n",
       " '3',\n",
       " 'We',\n",
       " 'wish',\n",
       " 'especially',\n",
       " 'thank',\n",
       " 'MCGM',\n",
       " 'officers',\n",
       " 'Mr.',\n",
       " 'Jagdish',\n",
       " 'Talreja',\n",
       " 'Mr.',\n",
       " 'Dinesh',\n",
       " 'Naik',\n",
       " 'Mr.',\n",
       " 'Hiren',\n",
       " 'Daftardar',\n",
       " 'Ms.',\n",
       " 'Anita',\n",
       " 'Naik',\n",
       " 'continual',\n",
       " 'support',\n",
       " 'since',\n",
       " 'beginning',\n",
       " 'project',\n",
       " 'help',\n",
       " 'towards',\n",
       " 'familiarization',\n",
       " 'data',\n",
       " 'collection',\n",
       " 'They',\n",
       " 'instrumental',\n",
       " 'helping',\n",
       " 'contact',\n",
       " 'various',\n",
       " 'MCGM',\n",
       " 'departments',\n",
       " 'well',\n",
       " 'helping',\n",
       " 'establish',\n",
       " 'contact',\n",
       " 'personnel',\n",
       " 'government',\n",
       " 'departments',\n",
       " 'organizations',\n",
       " 'Many',\n",
       " 'thanks',\n",
       " 'MCGM',\n",
       " 'team',\n",
       " 'deploying',\n",
       " 'personnel',\n",
       " 'particularly',\n",
       " 'Mr.',\n",
       " 'Prasad',\n",
       " 'Gharat',\n",
       " 'extensive',\n",
       " 'field',\n",
       " 'visits',\n",
       " 'helped',\n",
       " 'understanding',\n",
       " 'actual',\n",
       " 'ground',\n",
       " 'conditions',\n",
       " '........................................................................................',\n",
       " '3',\n",
       " 'BEST',\n",
       " '...............................................................................................................................',\n",
       " '.................',\n",
       " '5',\n",
       " 'Brihanmumbai',\n",
       " 'Electric',\n",
       " 'Supply',\n",
       " 'Transport',\n",
       " 'Undertaking',\n",
       " '..............................................................',\n",
       " '5',\n",
       " 'CIDCO',\n",
       " '...............................................................................................................................',\n",
       " '..............',\n",
       " '5',\n",
       " 'City',\n",
       " 'Industrial',\n",
       " 'Development',\n",
       " 'Corporation',\n",
       " '...............................................................................',\n",
       " '5',\n",
       " 'CTP',\n",
       " '...............................................................................................................................',\n",
       " '..................',\n",
       " '5',\n",
       " 'Comprehensive',\n",
       " 'Transportation',\n",
       " 'Plan',\n",
       " '...............................................................................................',\n",
       " '5',\n",
       " 'DP',\n",
       " '...............................................................................................................................',\n",
       " '....................',\n",
       " '5',\n",
       " 'Development',\n",
       " 'Plan',\n",
       " '..........................................................................................................................',\n",
       " '5',\n",
       " 'DPGM34',\n",
       " '...............................................................................................................................',\n",
       " '..........',\n",
       " '5',\n",
       " 'Development',\n",
       " 'Plan',\n",
       " 'Greater',\n",
       " 'Mumbai',\n",
       " '2034',\n",
       " '.......................................................................................',\n",
       " '5',\n",
       " 'DCR',\n",
       " '...............................................................................................................................',\n",
       " '..................',\n",
       " '5',\n",
       " 'Development',\n",
       " 'Control',\n",
       " 'Regulations',\n",
       " '...................................................................................................',\n",
       " '5',\n",
       " 'DGPS',\n",
       " '...........................................................................................................................',\n",
       " '....................',\n",
       " '5',\n",
       " 'Digital',\n",
       " 'Global',\n",
       " 'Positioning',\n",
       " 'System',\n",
       " '...................................................................................................',\n",
       " '5',\n",
       " 'DPGM',\n",
       " '...............................................................................................................................',\n",
       " '..............',\n",
       " '5',\n",
       " 'Development',\n",
       " 'Plan',\n",
       " 'Greater',\n",
       " 'Mumbai',\n",
       " '...........................................................................................',\n",
       " '5',\n",
       " 'ELU',\n",
       " '...............................................................................................................................',\n",
       " '..................',\n",
       " '5',\n",
       " 'Existing',\n",
       " 'Land',\n",
       " 'use',\n",
       " '.............................................................................................................................',\n",
       " '5',\n",
       " 'FSI',\n",
       " '...............................................................................................................................',\n",
       " '....................',\n",
       " '5',\n",
       " 'Floor',\n",
       " 'Space',\n",
       " 'Index',\n",
       " '............................................................................................................................',\n",
       " '5',\n",
       " 'GIS',\n",
       " '...............................................................................................................................',\n",
       " '...................',\n",
       " '5']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c669f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mr.Jagdish Talreja', 'Mr.Dinesh Naik', 'Mr.Hiren Daftardar', 'Ms.Anita Naik', 'Mr.Prasad Gharat']\n"
     ]
    }
   ],
   "source": [
    "name_list=list()\n",
    "check=['Mr.','Mrs.', 'Ms.']\n",
    "for idx, token in enumerate(tokens):\n",
    "    if token.startswith(tuple(check)) and idx<(len(tokens)-1):\n",
    "        name=token+tokens[idx+1] + ' ' +tokens[idx+2]\n",
    "        name_list.append(name)\n",
    "print(name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5931442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Obtaining dependency information for python-docx from https://files.pythonhosted.org/packages/3e/3d/330d9efbdb816d3f60bf2ad92f05e1708e4a1b9abe80461ac3444c83f749/python_docx-1.1.2-py3-none-any.whl.metadata\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\gunti\\anaconda3\\lib\\site-packages (from python-docx) (4.9.3)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\gunti\\anaconda3\\lib\\site-packages (from python-docx) (4.12.2)\n",
      "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "   ---------------------------------------- 0.0/244.3 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/244.3 kB ? eta -:--:--\n",
      "   ---- ---------------------------------- 30.7/244.3 kB 660.6 kB/s eta 0:00:01\n",
      "   -------------- ------------------------ 92.2/244.3 kB 871.5 kB/s eta 0:00:01\n",
      "   -------------- ------------------------ 92.2/244.3 kB 871.5 kB/s eta 0:00:01\n",
      "   -------------- ------------------------ 92.2/244.3 kB 871.5 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 194.6/244.3 kB 737.3 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 235.5/244.3 kB 758.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- 244.3/244.3 kB 713.6 kB/s eta 0:00:00\n",
      "Installing collected packages: python-docx\n",
      "Successfully installed python-docx-1.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "557bfdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3b891ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = open(\"file.docx\",\"rb\")\n",
    "document = docx.Document(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54e083cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   BDA Holiday AssignmentK Sai kiran(2211CS020233)-AIML(Gamma)Q 1: Handling Imbalanced DatasetsIn [4]: !pip install imbalanced-learnDefaulting to user installation because normal site-packages is not writeable Requirement already satisfied: imbalanced-learn in c:\\users\\hp\\appdata\\roaming\\pyt hon\\python39\\site-packages (0.12.4)Requirement already satisfied: scikit-learn>=1.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.0.2)Requirement already satisfied: scipy>=1.5.0 in c:\\programdata\\anaconda3\\lib\\site-p ackages (from imbalanced-learn) (1.9.1)Requirement already satisfied: joblib>=1.1.1 in c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages (from imbalanced-learn) (1.4.2)Requirement already satisfied: numpy>=1.17.3 in c:\\programdata\\anaconda3\\lib\\sitepackages (from imbalanced-learn) (1.21.5) Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\li b\\site-packages (from imbalanced-learn) (2.2.0)In [5]:Original class distribution:0\t900 1100 dtype:int64Balanced class distribution:0\t900 1900 dtype:int64Q 2: Optimal Clusters for K-meansIn [6]:Q 3: Dimensionality Reduction (PCA)In [7]:           Explained Variance Ratio: [0.42747748 0.38520658]Q 4: Correlations in a DatasetIn [8]:Correlation Matrix:A B\tC\tDA 1.000000 -0.120000 -0.064992 0.109141B -0.120000 1.000000 -0.084111 0.080800C -0.064992 -0.084111 1.000000 0.009066D 0.109141 0.080800 0.009066 1.000000Q 5: Handling Missing ValuesIn [9]:Original Data with NaNs: A\tB\tC0 1.0 NaN 1.01 2.0 2.0 NaNNaN 3.0 NaN4.0 4.0 4.0Data after Imputation:A\tB\tC0 1.000000 3.0 1.01 2.000000 2.0 2.52 2.333333 3.0 2.53 4.000000 4.0 4.0Q 6: Detect and Remove DuplicatesIn [10]:Original Data: A B\tC0 1 5\t91 2 6 102 2 6 103 4 8 12Data after removing duplicates:Q 9: Linear and Logistic RegressionIn [13]:# Import Librariesfrom sklearn.linear_model import LinearRegression, LogisticRegression t from sklearn.metrics import mean_squared_error, accuracy_score fromsklearn.model_selection import train_test_splitfrom sklearn.datasets import make_classification, make_regressiont # Create datasets# For Linear RegressionX_reg, y_reg = make_regression(n_samples=1000, n_features=5, noise=0.1, random_stat X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg,# For Logistic RegressionX_clf, y_clf = make_classification(n_samples=1000, n_features=5, n_classes=2, rando X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(X_clf, y_clf,# Linear Regressionlinear_model = LinearRegression() linear_model.fit(X_train_reg, y_train_reg)# Predictions and evaluation for Linear Regression y_pred_linear= linear_model.predict(X_test_reg)print(\"Linear Regression MSE:\", mean_squared_error(y_test_reg, y_pred_linear))))# Logistic Regressionlogistic_model = LogisticRegression() logistic_model.fit(X_train_clf, y_train_clf)# Predictions and evaluation for Logistic Regression y_pred_logistic= logistic_model.predict(X_test_clf)print(\"Logistic Regression Accuracy:\", accuracy_score(y_test_clf, y_pred_logisticLinear Regression MSE: 0.011098494768118168 Logistic Regression Accuracy: 0.89Q10: Lag Features for Time-Series DataIn [15]:Time-Series Data with Lag Features:Date\tValue\tLag_1\tLag_2 0 2020-01-01 0.035747\t NaN\t NaN9 2020-01-10 0.467016 0.241467 0.561908In [ ]:\n"
     ]
    }
   ],
   "source": [
    "docu=\"\"\n",
    "for para in document.paragraphs:\n",
    "    docu += para.text\n",
    "print(docu)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82fb2b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The content of the paragraph 0 is :    BDA Holiday Assignment\n",
      "\n",
      "The content of the paragraph 1 is : K Sai kiran(2211CS020233)-AIML(Gamma)\n",
      "\n",
      "The content of the paragraph 2 is : \n",
      "\n",
      "The content of the paragraph 3 is : Q 1: Handling Imbalanced Datasets\n",
      "\n",
      "The content of the paragraph 4 is : In [4]: !pip install imbalanced-learn\n",
      "\n",
      "The content of the paragraph 5 is : Defaulting to user installation because normal site-packages is not writeable Requirement already satisfied: imbalanced-learn in c:\\users\\hp\\appdata\\roaming\\pyt hon\\python39\\site-packages (0.12.4)\n",
      "\n",
      "The content of the paragraph 6 is : Requirement already satisfied: scikit-learn>=1.0.2 in c:\\programdata\\anaconda3\\lib\n",
      "\n",
      "The content of the paragraph 7 is : \\site-packages (from imbalanced-learn) (1.0.2)\n",
      "\n",
      "The content of the paragraph 8 is : Requirement already satisfied: scipy>=1.5.0 in c:\\programdata\\anaconda3\\lib\\site-p ackages (from imbalanced-learn) (1.9.1)\n",
      "\n",
      "The content of the paragraph 9 is : Requirement already satisfied: joblib>=1.1.1 in c:\\users\\hp\\appdata\\roaming\\python\n",
      "\n",
      "The content of the paragraph 10 is : \\python39\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "\n",
      "The content of the paragraph 11 is : Requirement already satisfied: numpy>=1.17.3 in c:\\programdata\\anaconda3\\lib\\sitepackages (from imbalanced-learn) (1.21.5) Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\li b\\site-packages (from imbalanced-learn) (2.2.0)\n",
      "\n",
      "The content of the paragraph 12 is : \n",
      "\n",
      "The content of the paragraph 13 is : In [5]:\n",
      "\n",
      "The content of the paragraph 14 is : \n",
      "\n",
      "The content of the paragraph 15 is : \n",
      "\n",
      "The content of the paragraph 16 is : \n",
      "\n",
      "The content of the paragraph 17 is : \n",
      "\n",
      "The content of the paragraph 18 is : \n",
      "\n",
      "The content of the paragraph 19 is : \n",
      "\n",
      "The content of the paragraph 20 is : \n",
      "\n",
      "The content of the paragraph 21 is : \n",
      "\n",
      "The content of the paragraph 22 is : \n",
      "\n",
      "The content of the paragraph 23 is : \n",
      "\n",
      "The content of the paragraph 24 is : \n",
      "\n",
      "The content of the paragraph 25 is : \n",
      "\n",
      "The content of the paragraph 26 is : \n",
      "\n",
      "The content of the paragraph 27 is : \n",
      "\n",
      "The content of the paragraph 28 is : \n",
      "\n",
      "The content of the paragraph 29 is : \n",
      "\n",
      "The content of the paragraph 30 is : \n",
      "\n",
      "The content of the paragraph 31 is : \n",
      "\n",
      "The content of the paragraph 32 is : \n",
      "\n",
      "The content of the paragraph 33 is : \n",
      "\n",
      "The content of the paragraph 34 is : \n",
      "\n",
      "The content of the paragraph 35 is : \n",
      "\n",
      "The content of the paragraph 36 is : \n",
      "\n",
      "The content of the paragraph 37 is : \n",
      "\n",
      "The content of the paragraph 38 is : Original class distribution:\n",
      "\n",
      "The content of the paragraph 39 is : 0\t900 1\n",
      "\n",
      "The content of the paragraph 40 is : 100 dtype:\n",
      "\n",
      "The content of the paragraph 41 is : int64\n",
      "\n",
      "The content of the paragraph 42 is : Balanced class distribution:\n",
      "\n",
      "The content of the paragraph 43 is : 0\t900 1\n",
      "\n",
      "The content of the paragraph 44 is : 900 dtype:\n",
      "\n",
      "The content of the paragraph 45 is : int64\n",
      "\n",
      "The content of the paragraph 46 is : \n",
      "\n",
      "The content of the paragraph 47 is : Q 2: Optimal Clusters for K-means\n",
      "\n",
      "The content of the paragraph 48 is : \n",
      "\n",
      "The content of the paragraph 49 is : In [6]:\n",
      "\n",
      "The content of the paragraph 50 is : \n",
      "\n",
      "The content of the paragraph 51 is : \n",
      "\n",
      "The content of the paragraph 52 is : \n",
      "\n",
      "The content of the paragraph 53 is : \n",
      "\n",
      "The content of the paragraph 54 is : \n",
      "\n",
      "The content of the paragraph 55 is : \n",
      "\n",
      "The content of the paragraph 56 is : \n",
      "\n",
      "The content of the paragraph 57 is : \n",
      "\n",
      "The content of the paragraph 58 is : \n",
      "\n",
      "The content of the paragraph 59 is : \n",
      "\n",
      "The content of the paragraph 60 is : \n",
      "\n",
      "The content of the paragraph 61 is : \n",
      "\n",
      "The content of the paragraph 62 is : \n",
      "\n",
      "The content of the paragraph 63 is : \n",
      "\n",
      "The content of the paragraph 64 is : \n",
      "\n",
      "The content of the paragraph 65 is : \n",
      "\n",
      "The content of the paragraph 66 is : \n",
      "\n",
      "The content of the paragraph 67 is : \n",
      "\n",
      "The content of the paragraph 68 is : \n",
      "\n",
      "The content of the paragraph 69 is : \n",
      "\n",
      "The content of the paragraph 70 is : \n",
      "\n",
      "The content of the paragraph 71 is : \n",
      "\n",
      "The content of the paragraph 72 is : \n",
      "\n",
      "The content of the paragraph 73 is : \n",
      "\n",
      "The content of the paragraph 74 is : Q 3: Dimensionality Reduction (PCA)\n",
      "\n",
      "The content of the paragraph 75 is : \n",
      "\n",
      "The content of the paragraph 76 is : In [7]:\n",
      "\n",
      "The content of the paragraph 77 is : \n",
      "\n",
      "The content of the paragraph 78 is : \n",
      "\n",
      "The content of the paragraph 79 is :            Explained Variance Ratio: [0.42747748 0.38520658]\n",
      "\n",
      "The content of the paragraph 80 is : \n",
      "\n",
      "The content of the paragraph 81 is : \n",
      "\n",
      "The content of the paragraph 82 is : \n",
      "\n",
      "The content of the paragraph 83 is : \n",
      "\n",
      "The content of the paragraph 84 is : \n",
      "\n",
      "The content of the paragraph 85 is : \n",
      "\n",
      "The content of the paragraph 86 is : \n",
      "\n",
      "The content of the paragraph 87 is : \n",
      "\n",
      "The content of the paragraph 88 is : \n",
      "\n",
      "The content of the paragraph 89 is : \n",
      "\n",
      "The content of the paragraph 90 is : \n",
      "\n",
      "The content of the paragraph 91 is : \n",
      "\n",
      "The content of the paragraph 92 is : \n",
      "\n",
      "The content of the paragraph 93 is : \n",
      "\n",
      "The content of the paragraph 94 is : \n",
      "\n",
      "The content of the paragraph 95 is : Q 4: Correlations in a Dataset\n",
      "\n",
      "The content of the paragraph 96 is : \n",
      "\n",
      "The content of the paragraph 97 is : In [8]:\n",
      "\n",
      "The content of the paragraph 98 is : \n",
      "\n",
      "The content of the paragraph 99 is : \n",
      "\n",
      "The content of the paragraph 100 is : \n",
      "\n",
      "The content of the paragraph 101 is : \n",
      "\n",
      "The content of the paragraph 102 is : \n",
      "\n",
      "The content of the paragraph 103 is : \n",
      "\n",
      "The content of the paragraph 104 is : \n",
      "\n",
      "The content of the paragraph 105 is : \n",
      "\n",
      "The content of the paragraph 106 is : \n",
      "\n",
      "The content of the paragraph 107 is : \n",
      "\n",
      "The content of the paragraph 108 is : \n",
      "\n",
      "The content of the paragraph 109 is : \n",
      "\n",
      "The content of the paragraph 110 is : \n",
      "\n",
      "The content of the paragraph 111 is : \n",
      "\n",
      "The content of the paragraph 112 is : \n",
      "\n",
      "The content of the paragraph 113 is : \n",
      "\n",
      "The content of the paragraph 114 is : \n",
      "\n",
      "The content of the paragraph 115 is : \n",
      "\n",
      "The content of the paragraph 116 is : \n",
      "\n",
      "The content of the paragraph 117 is : \n",
      "\n",
      "The content of the paragraph 118 is : \n",
      "\n",
      "The content of the paragraph 119 is : \n",
      "\n",
      "The content of the paragraph 120 is : \n",
      "\n",
      "The content of the paragraph 121 is : \n",
      "\n",
      "The content of the paragraph 122 is : \n",
      "\n",
      "The content of the paragraph 123 is : Correlation Matrix:\n",
      "\n",
      "The content of the paragraph 124 is : A B\tC\tDA 1.000000 -0.120000 -0.064992 0.109141\n",
      "\n",
      "The content of the paragraph 125 is : B -0.120000 1.000000 -0.084111 0.080800\n",
      "\n",
      "The content of the paragraph 126 is : C -0.064992 -0.084111 1.000000 0.009066\n",
      "\n",
      "The content of the paragraph 127 is : D 0.109141 0.080800 0.009066 1.000000\n",
      "\n",
      "The content of the paragraph 128 is : \n",
      "\n",
      "The content of the paragraph 129 is : \n",
      "\n",
      "The content of the paragraph 130 is : \n",
      "\n",
      "The content of the paragraph 131 is : Q 5: Handling Missing Values\n",
      "\n",
      "The content of the paragraph 132 is : \n",
      "\n",
      "The content of the paragraph 133 is : In [9]:\n",
      "\n",
      "The content of the paragraph 134 is : \n",
      "\n",
      "The content of the paragraph 135 is : \n",
      "\n",
      "The content of the paragraph 136 is : \n",
      "\n",
      "The content of the paragraph 137 is : \n",
      "\n",
      "The content of the paragraph 138 is : \n",
      "\n",
      "The content of the paragraph 139 is : \n",
      "\n",
      "The content of the paragraph 140 is : \n",
      "\n",
      "The content of the paragraph 141 is : \n",
      "\n",
      "The content of the paragraph 142 is : \n",
      "\n",
      "The content of the paragraph 143 is : \n",
      "\n",
      "The content of the paragraph 144 is : \n",
      "\n",
      "The content of the paragraph 145 is : \n",
      "\n",
      "The content of the paragraph 146 is : \n",
      "\n",
      "The content of the paragraph 147 is : \n",
      "\n",
      "The content of the paragraph 148 is : \n",
      "\n",
      "The content of the paragraph 149 is : \n",
      "\n",
      "The content of the paragraph 150 is : \n",
      "\n",
      "The content of the paragraph 151 is : \n",
      "\n",
      "The content of the paragraph 152 is : \n",
      "\n",
      "The content of the paragraph 153 is : \n",
      "\n",
      "The content of the paragraph 154 is : Original Data with NaNs: A\tB\tC\n",
      "\n",
      "The content of the paragraph 155 is : 0 1.0 NaN 1.0\n",
      "\n",
      "The content of the paragraph 156 is : 1 2.0 2.0 NaN\n",
      "\n",
      "The content of the paragraph 157 is : NaN 3.0 NaN\n",
      "\n",
      "The content of the paragraph 158 is : 4.0 4.0 4.0\n",
      "\n",
      "The content of the paragraph 159 is : \n",
      "\n",
      "The content of the paragraph 160 is : Data after Imputation:\n",
      "\n",
      "The content of the paragraph 161 is : A\tB\tC\n",
      "\n",
      "The content of the paragraph 162 is : 0 1.000000 3.0 1.0\n",
      "\n",
      "The content of the paragraph 163 is : 1 2.000000 2.0 2.5\n",
      "\n",
      "The content of the paragraph 164 is : 2 2.333333 3.0 2.5\n",
      "\n",
      "The content of the paragraph 165 is : 3 4.000000 4.0 4.0\n",
      "\n",
      "The content of the paragraph 166 is : Q 6: Detect and Remove Duplicates\n",
      "\n",
      "The content of the paragraph 167 is : \n",
      "\n",
      "The content of the paragraph 168 is : In [10]:\n",
      "\n",
      "The content of the paragraph 169 is : \n",
      "\n",
      "The content of the paragraph 170 is : \n",
      "\n",
      "The content of the paragraph 171 is : \n",
      "\n",
      "The content of the paragraph 172 is : \n",
      "\n",
      "The content of the paragraph 173 is : \n",
      "\n",
      "The content of the paragraph 174 is : \n",
      "\n",
      "The content of the paragraph 175 is : \n",
      "\n",
      "The content of the paragraph 176 is : \n",
      "\n",
      "The content of the paragraph 177 is : \n",
      "\n",
      "The content of the paragraph 178 is : \n",
      "\n",
      "The content of the paragraph 179 is : \n",
      "\n",
      "The content of the paragraph 180 is : \n",
      "\n",
      "The content of the paragraph 181 is : \n",
      "\n",
      "The content of the paragraph 182 is : Original Data: A B\tC\n",
      "\n",
      "The content of the paragraph 183 is : 0 1 5\t9\n",
      "\n",
      "The content of the paragraph 184 is : 1 2 6 10\n",
      "\n",
      "The content of the paragraph 185 is : 2 2 6 10\n",
      "\n",
      "The content of the paragraph 186 is : 3 4 8 12\n",
      "\n",
      "The content of the paragraph 187 is : \n",
      "\n",
      "The content of the paragraph 188 is : Data after removing duplicates:\n",
      "\n",
      "The content of the paragraph 189 is : \n",
      "\n",
      "The content of the paragraph 190 is : \n",
      "\n",
      "The content of the paragraph 191 is : \n",
      "\n",
      "The content of the paragraph 192 is : \n",
      "\n",
      "The content of the paragraph 193 is : \n",
      "\n",
      "The content of the paragraph 194 is : \n",
      "\n",
      "The content of the paragraph 195 is : \n",
      "\n",
      "The content of the paragraph 196 is : \n",
      "\n",
      "The content of the paragraph 197 is : \n",
      "\n",
      "The content of the paragraph 198 is : \n",
      "\n",
      "The content of the paragraph 199 is : \n",
      "\n",
      "The content of the paragraph 200 is : \n",
      "\n",
      "The content of the paragraph 201 is : \n",
      "\n",
      "The content of the paragraph 202 is : \n",
      "\n",
      "The content of the paragraph 203 is : \n",
      "\n",
      "The content of the paragraph 204 is : \n",
      "\n",
      "The content of the paragraph 205 is : \n",
      "\n",
      "The content of the paragraph 206 is : \n",
      "\n",
      "The content of the paragraph 207 is : \n",
      "\n",
      "The content of the paragraph 208 is : \n",
      "\n",
      "The content of the paragraph 209 is : \n",
      "\n",
      "The content of the paragraph 210 is : \n",
      "\n",
      "The content of the paragraph 211 is : \n",
      "\n",
      "The content of the paragraph 212 is : \n",
      "\n",
      "The content of the paragraph 213 is : \n",
      "\n",
      "The content of the paragraph 214 is : \n",
      "\n",
      "The content of the paragraph 215 is : \n",
      "\n",
      "The content of the paragraph 216 is : \n",
      "\n",
      "The content of the paragraph 217 is : \n",
      "\n",
      "The content of the paragraph 218 is : \n",
      "\n",
      "The content of the paragraph 219 is : \n",
      "\n",
      "The content of the paragraph 220 is : \n",
      "\n",
      "The content of the paragraph 221 is : \n",
      "\n",
      "The content of the paragraph 222 is : \n",
      "\n",
      "The content of the paragraph 223 is : \n",
      "\n",
      "The content of the paragraph 224 is : \n",
      "\n",
      "The content of the paragraph 225 is : \n",
      "\n",
      "The content of the paragraph 226 is : \n",
      "\n",
      "The content of the paragraph 227 is : \n",
      "\n",
      "The content of the paragraph 228 is : \n",
      "\n",
      "The content of the paragraph 229 is : \n",
      "\n",
      "The content of the paragraph 230 is : Q 9: Linear and Logistic Regression\n",
      "\n",
      "The content of the paragraph 231 is : \n",
      "\n",
      "The content of the paragraph 232 is : In [13]:\n",
      "\n",
      "The content of the paragraph 233 is : # Import Libraries\n",
      "\n",
      "The content of the paragraph 234 is : from sklearn.linear_model import LinearRegression, LogisticRegression t from sklearn.metrics import mean_squared_error, accuracy_score from\n",
      "\n",
      "The content of the paragraph 235 is : sklearn.model_selection import train_test_split\n",
      "\n",
      "The content of the paragraph 236 is : from sklearn.datasets import make_classification, make_regression\n",
      "\n",
      "The content of the paragraph 237 is : \n",
      "\n",
      "The content of the paragraph 238 is : t # Create datasets\n",
      "\n",
      "The content of the paragraph 239 is : # For Linear Regression\n",
      "\n",
      "The content of the paragraph 240 is : X_reg, y_reg = make_regression(n_samples=1000, n_features=5, noise=0.1, random_stat X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg,\n",
      "\n",
      "The content of the paragraph 241 is : \n",
      "\n",
      "The content of the paragraph 242 is : # For Logistic Regression\n",
      "\n",
      "The content of the paragraph 243 is : X_clf, y_clf = make_classification(n_samples=1000, n_features=5, n_classes=2, rando X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(X_clf, y_clf,\n",
      "\n",
      "The content of the paragraph 244 is : \n",
      "\n",
      "The content of the paragraph 245 is : # Linear Regression\n",
      "\n",
      "The content of the paragraph 246 is : linear_model = LinearRegression() linear_model.fit(X_train_reg, y_train_reg)\n",
      "\n",
      "The content of the paragraph 247 is : \n",
      "\n",
      "The content of the paragraph 248 is : # Predictions and evaluation for Linear Regression y_pred_linear\n",
      "\n",
      "The content of the paragraph 249 is : = linear_model.predict(X_test_reg)\n",
      "\n",
      "The content of the paragraph 250 is : print(\"Linear Regression MSE:\", mean_squared_error(y_test_reg, y_pred_linear))\n",
      "\n",
      "The content of the paragraph 251 is : ))\n",
      "\n",
      "The content of the paragraph 252 is : # Logistic Regression\n",
      "\n",
      "The content of the paragraph 253 is : logistic_model = LogisticRegression() logistic_model.fit(X_train_clf, y_train_clf)\n",
      "\n",
      "The content of the paragraph 254 is : \n",
      "\n",
      "The content of the paragraph 255 is : # Predictions and evaluation for Logistic Regression y_pred_logistic\n",
      "\n",
      "The content of the paragraph 256 is : = logistic_model.predict(X_test_clf)\n",
      "\n",
      "The content of the paragraph 257 is : print(\"Logistic Regression Accuracy:\", accuracy_score(y_test_clf, y_pred_logistic\n",
      "\n",
      "The content of the paragraph 258 is : \n",
      "\n",
      "The content of the paragraph 259 is : Linear Regression MSE: 0.011098494768118168 Logistic Regression Accuracy: 0.89\n",
      "\n",
      "The content of the paragraph 260 is : Q10: Lag Features for Time-Series Data\n",
      "\n",
      "The content of the paragraph 261 is : \n",
      "\n",
      "The content of the paragraph 262 is : In [15]:\n",
      "\n",
      "The content of the paragraph 263 is : \n",
      "\n",
      "The content of the paragraph 264 is : \n",
      "\n",
      "The content of the paragraph 265 is : \n",
      "\n",
      "The content of the paragraph 266 is : \n",
      "\n",
      "The content of the paragraph 267 is : \n",
      "\n",
      "The content of the paragraph 268 is : \n",
      "\n",
      "The content of the paragraph 269 is : \n",
      "\n",
      "The content of the paragraph 270 is : \n",
      "\n",
      "The content of the paragraph 271 is : \n",
      "\n",
      "The content of the paragraph 272 is : \n",
      "\n",
      "The content of the paragraph 273 is : \n",
      "\n",
      "The content of the paragraph 274 is : \n",
      "\n",
      "The content of the paragraph 275 is : \n",
      "\n",
      "The content of the paragraph 276 is : \n",
      "\n",
      "The content of the paragraph 277 is : \n",
      "\n",
      "The content of the paragraph 278 is : \n",
      "\n",
      "The content of the paragraph 279 is : \n",
      "\n",
      "The content of the paragraph 280 is : \n",
      "\n",
      "The content of the paragraph 281 is : Time-Series Data with Lag Features:\n",
      "\n",
      "The content of the paragraph 282 is : Date\tValue\tLag_1\tLag_2 0 2020-01-01 0.035747\t NaN\t NaN\n",
      "\n",
      "The content of the paragraph 283 is : \n",
      "\n",
      "The content of the paragraph 284 is : 9 2020-01-10 0.467016 0.241467 0.561908In [ ]:\n",
      "\n",
      "The content of the paragraph 285 is : \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(document.paragraphs)):\n",
    "    print(\"The content of the paragraph \"+ str(i)+\" is : \" + document.paragraphs[i].text+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae670221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Obtaining dependency information for bs4 from https://files.pythonhosted.org/packages/51/bb/bf7aab772a159614954d84aa832c129624ba6c32faa559dfb200a534e50b/bs4-0.0.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\gunti\\anaconda3\\lib\\site-packages (from bs4) (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\gunti\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.4)\n",
      "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f55e91c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as urllib2\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5a3cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = urllib2.urlopen('https://en.wikipedia.org/wiki/Natural_language_processing')\n",
    "html_doc = response.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcf7684a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html class=\"client-nojs vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-page-tools-pinned-disabled vector-feature-toc-pinned-clientpref-1 vector-feature-main-menu-pinned-disabled vector-feature-limited-width-clientpref-1 vector-feature-limited-width-content-enabled vector-feature-custom-font-size-clientpref-1 vector-feature-appearance-pinned-clientpref-1 vector-feature-night-mode-enabled skin-theme-clientpref-day vector-sticky-header-enabled vector-toc-available\" dir=\"ltr\" lang=\"en\">\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <title>\n",
      "   Natural language processing - Wikipedia\n",
      "  </title>\n",
      "  <script>\n",
      "   (function(){var className=\"client-js vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-page-tools-pinned-disabled vector-feature-toc-pinned-clientpref-1 vector-feature-main-menu-pinned-disabled vector-feature-limited-width-clientpref-1 vector-feature-limited-width-content-enabled vector-feature-custom-font-size-clientpref-1 vector-feature-appearance-pinned-clientpref-1 vector-feature-night-mode-enabled skin-theme-clientpref-day vector-sticky-header-enabled vector-toc-available\";var cookie=document.cookie.match(/(?:^|; )enwikimwclientpreferences=([^;]+)/);if(cookie){cookie[1].split('%2C').forEach(function(pref){className=className.replace(new RegExp('(^| )'+pref.replace(/-clientpref-\\w+$|[^\\w-]+/g,'')+'-clientpref-\\\\w+( |$)'),'$1'+pref+'$2');});}document.documentElement.className=className;}());RLCONF={\"wgBreakFrames\":false,\"wgSeparatorTransformTable\":[\"\",\"\"],\"wgDigitTransformTable\":[\"\",\"\"],\"wgDefaultDateFormat\":\"dmy\",\n",
      "\"wgMonthNames\":[\"\",\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],\"wgRequestId\":\"bb8cccbb-931f-4281-aaf8-3aff8c9effb8\",\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":false,\"wgNamespaceNumber\":0,\"wgPageName\":\"Natural_language_processing\",\"wgTitle\":\"Natural language processing\",\"wgCurRevisionId\":1274942014,\"wgRevisionId\":1274942014,\"wgArticleId\":21652,\"wgIsArticle\":true,\"wgIsRedirect\":false,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[\"All accuracy disputes\",\"Accuracy disputes from December 2013\",\"Harv and Sfn no-target errors\",\"CS1 errors: periodical ignored\",\"CS1 maint: location\",\"Articles with short description\",\"Short description is different from Wikidata\",\"Articles needing additional references from May 2024\",\"All articles needing additional references\",\"All articles with unsourced statements\",\"Articles with unsourced statements from May 2024\",\"Commons category link from Wikidata\",\n",
      "\"Natural language processing\",\"Computational fields of study\",\"Computational linguistics\",\"Speech recognition\"],\"wgPageViewLanguage\":\"en\",\"wgPageContentLanguage\":\"en\",\"wgPageContentModel\":\"wikitext\",\"wgRelevantPageName\":\"Natural_language_processing\",\"wgRelevantArticleId\":21652,\"wgIsProbablyEditable\":true,\"wgRelevantPageIsProbablyEditable\":true,\"wgRestrictionEdit\":[],\"wgRestrictionMove\":[],\"wgNoticeProject\":\"wikipedia\",\"wgCiteReferencePreviewsActive\":false,\"wgFlaggedRevsParams\":{\"tags\":{\"status\":{\"levels\":1}}},\"wgMediaViewerOnClick\":true,\"wgMediaViewerEnabledByDefault\":true,\"wgPopupsFlags\":0,\"wgVisualEditor\":{\"pageLanguageCode\":\"en\",\"pageLanguageDir\":\"ltr\",\"pageVariantFallbacks\":\"en\"},\"wgMFDisplayWikibaseDescriptions\":{\"search\":true,\"watchlist\":true,\"tagline\":false,\"nearby\":true},\"wgWMESchemaEditAttemptStepOversample\":false,\"wgWMEPageLength\":60000,\"wgEditSubmitButtonLabelPublish\":true,\"wgULSPosition\":\"interlanguage\",\"wgULSisCompactLinksEnabled\":false,\"wgVector2022LanguageInHeader\":true,\n",
      "\"wgULSisLanguageSelectorEmpty\":false,\"wgWikibaseItemId\":\"Q30642\",\"wgCheckUserClientHintsHeadersJsApi\":[\"brands\",\"architecture\",\"bitness\",\"fullVersionList\",\"mobile\",\"model\",\"platform\",\"platformVersion\"],\"GEHomepageSuggestedEditsEnableTopics\":true,\"wgGETopicsMatchModeEnabled\":false,\"wgGEStructuredTaskRejectionReasonTextInputEnabled\":false,\"wgGELevelingUpEnabledForUser\":false};RLSTATE={\"ext.globalCssJs.user.styles\":\"ready\",\"site.styles\":\"ready\",\"user.styles\":\"ready\",\"ext.globalCssJs.user\":\"ready\",\"user\":\"ready\",\"user.options\":\"loading\",\"ext.cite.styles\":\"ready\",\"ext.math.styles\":\"ready\",\"skins.vector.search.codex.styles\":\"ready\",\"skins.vector.styles\":\"ready\",\"skins.vector.icons\":\"ready\",\"jquery.makeCollapsible.styles\":\"ready\",\"ext.wikimediamessages.styles\":\"ready\",\"ext.visualEditor.desktopArticleTarget.noscript\":\"ready\",\"ext.uls.interlanguage\":\"ready\",\"wikibase.client.init\":\"ready\",\"ext.wikimediaBadges\":\"ready\"};RLPAGEMODULES=[\"ext.cite.ux-enhancements\",\"ext.scribunto.logs\",\"site\",\n",
      "\"mediawiki.page.ready\",\"jquery.makeCollapsible\",\"mediawiki.toc\",\"skins.vector.js\",\"ext.centralNotice.geoIP\",\"ext.centralNotice.startUp\",\"ext.gadget.ReferenceTooltips\",\"ext.gadget.switcher\",\"ext.urlShortener.toolbar\",\"ext.centralauth.centralautologin\",\"mmv.bootstrap\",\"ext.popups\",\"ext.visualEditor.desktopArticleTarget.init\",\"ext.visu\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "strhtm = soup.prettify()\n",
    "print(strhtm[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657e0dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
